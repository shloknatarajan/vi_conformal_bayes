{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04035a62",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "760eb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "from pyro.infer.autoguide.initialization import init_to_value\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import snakeviz\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist\n",
    "import random\n",
    "from sklearn.datasets import load_diabetes\n",
    "assert pyro.__version__.startswith('1.8.4')\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404a136",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef8d32",
   "metadata": {},
   "source": [
    "### Random Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c6427873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stdp_dataset(dim, num_examples, min_value, max_value):\n",
    "    X = np.random.random((num_examples + 1, dim)) * (max_value - min_value) + min_value\n",
    "    beta = np.random.random((dim)) * (max_value - min_value) + min_value\n",
    "\n",
    "    noise = np.random.normal(0, np.sqrt(max_value - min_value), num_examples + 1)\n",
    "    Y = X[:num_examples + 1] @ beta + noise\n",
    "\n",
    "    X = np.asfortranarray(X)\n",
    "    Y = np.asfortranarray(Y)\n",
    "    X /= np.linalg.norm(X, axis=0)\n",
    "    Y = (Y - Y.mean()) / Y.std()\n",
    "    Y = Y * max_value\n",
    "\n",
    "    Y = Y/np.linalg.norm(Y)\n",
    "\n",
    "    return X, Y, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5eb99929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, beta = generate_stdp_dataset(10, 442, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69c26b",
   "metadata": {},
   "source": [
    "### Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdd898",
   "metadata": {},
   "source": [
    "X, Y = load_diabetes(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf12e4",
   "metadata": {},
   "source": [
    "print(Y[0:3])\n",
    "Y = (Y - Y.mean()) / Y.std()\n",
    "print(Y[0:3])\n",
    "X = X / np.linalg.norm(X)\n",
    "print(X[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec7c5b",
   "metadata": {},
   "source": [
    "### Set up X, Y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f901b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = copy.deepcopy(X)\n",
    "Y_train = copy.deepcopy(Y[:len(Y) - 1])\n",
    "X_train = [torch.tensor(member) for member in X_train]\n",
    "Y_train = [torch.tensor(member) for member in Y_train]\n",
    "last_y = Y[-1]\n",
    "dim = len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c750c4d",
   "metadata": {},
   "source": [
    "### Load dataset from pre-generated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6c66ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_datasets/dataset_0.pkl', 'rb') as infile:\n",
    "    variables = pickle.load(infile)\n",
    "    X_train = variables['x_train']\n",
    "    Y_train = variables['y_train']\n",
    "    last_y = variables['last_y']\n",
    "    dim = variables['dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9d469a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-0.0396, dtype=torch.float64), tensor(0.0560, dtype=torch.float64), tensor(0.0254, dtype=torch.float64), tensor(-0.0548, dtype=torch.float64), tensor(0.0105, dtype=torch.float64), tensor(-0.0536, dtype=torch.float64), tensor(0.0930, dtype=torch.float64), tensor(0.1202, dtype=torch.float64), tensor(0.0638, dtype=torch.float64), tensor(-0.0368, dtype=torch.float64), tensor(-0.1037, dtype=torch.float64), tensor(0.0125, dtype=torch.float64), tensor(-2.7243e-05, dtype=torch.float64), tensor(0.0224, dtype=torch.float64), tensor(0.0337, dtype=torch.float64), tensor(-0.0851, dtype=torch.float64), tensor(0.0305, dtype=torch.float64), tensor(-0.0274, dtype=torch.float64), tensor(0.0310, dtype=torch.float64), tensor(-0.0121, dtype=torch.float64), tensor(0.0402, dtype=torch.float64), tensor(0.0625, dtype=torch.float64), tensor(0.0798, dtype=torch.float64), tensor(-0.0841, dtype=torch.float64), tensor(-0.0498, dtype=torch.float64), tensor(0.0431, dtype=torch.float64), tensor(-0.0310, dtype=torch.float64), tensor(-0.0140, dtype=torch.float64), tensor(-0.0365, dtype=torch.float64), tensor(-0.1012, dtype=torch.float64), tensor(0.0232, dtype=torch.float64), tensor(-0.0061, dtype=torch.float64), tensor(-0.0551, dtype=torch.float64), tensor(-0.0192, dtype=torch.float64), tensor(-0.0392, dtype=torch.float64), tensor(-0.0619, dtype=torch.float64), tensor(0.0265, dtype=torch.float64), tensor(-0.0347, dtype=torch.float64), tensor(-0.0489, dtype=torch.float64), tensor(0.0169, dtype=torch.float64), tensor(-0.0439, dtype=torch.float64), tensor(0.0115, dtype=torch.float64), tensor(-0.1077, dtype=torch.float64), tensor(0.0181, dtype=torch.float64), tensor(0.1160, dtype=torch.float64), tensor(0.0251, dtype=torch.float64), tensor(-0.0236, dtype=torch.float64), tensor(-0.0056, dtype=torch.float64), tensor(-0.0796, dtype=torch.float64), tensor(-0.0032, dtype=torch.float64), tensor(0.0336, dtype=torch.float64), tensor(-0.0664, dtype=torch.float64), tensor(-0.0209, dtype=torch.float64), tensor(-0.0271, dtype=torch.float64), tensor(0.0058, dtype=torch.float64), tensor(0.0216, dtype=torch.float64), tensor(0.0532, dtype=torch.float64), tensor(0.0416, dtype=torch.float64), tensor(0.0305, dtype=torch.float64), tensor(0.0213, dtype=torch.float64), tensor(0.0095, dtype=torch.float64), tensor(0.0007, dtype=torch.float64), tensor(-0.0230, dtype=torch.float64), tensor(0.0457, dtype=torch.float64), tensor(-0.0425, dtype=torch.float64), tensor(-0.0101, dtype=torch.float64), tensor(-0.1009, dtype=torch.float64), tensor(-0.0212, dtype=torch.float64), tensor(-0.0841, dtype=torch.float64), tensor(0.0031, dtype=torch.float64), tensor(-0.0628, dtype=torch.float64), tensor(-0.0020, dtype=torch.float64), tensor(0.0444, dtype=torch.float64), tensor(0.0811, dtype=torch.float64), tensor(0.0461, dtype=torch.float64), tensor(0.0608, dtype=torch.float64), tensor(-0.0359, dtype=torch.float64), tensor(-0.0312, dtype=torch.float64), tensor(0.0604, dtype=torch.float64), tensor(-0.0054, dtype=torch.float64), tensor(-0.0640, dtype=torch.float64), tensor(0.0622, dtype=torch.float64), tensor(0.0150, dtype=torch.float64), tensor(0.0584, dtype=torch.float64), tensor(-0.0299, dtype=torch.float64), tensor(0.0310, dtype=torch.float64), tensor(-0.0075, dtype=torch.float64), tensor(0.0227, dtype=torch.float64), tensor(0.0029, dtype=torch.float64), tensor(-0.0399, dtype=torch.float64), tensor(0.0179, dtype=torch.float64), tensor(0.0094, dtype=torch.float64), tensor(-0.0048, dtype=torch.float64), tensor(-0.0660, dtype=torch.float64), tensor(-0.0270, dtype=torch.float64), tensor(0.0416, dtype=torch.float64), tensor(-0.0023, dtype=torch.float64), tensor(0.0105, dtype=torch.float64), tensor(-0.0257, dtype=torch.float64), tensor(0.0746, dtype=torch.float64), tensor(0.0072, dtype=torch.float64), tensor(0.0325, dtype=torch.float64), tensor(-0.0007, dtype=torch.float64), tensor(0.0556, dtype=torch.float64), tensor(-0.0100, dtype=torch.float64), tensor(0.0626, dtype=torch.float64), tensor(-0.0374, dtype=torch.float64), tensor(0.0160, dtype=torch.float64), tensor(0.0348, dtype=torch.float64), tensor(0.0268, dtype=torch.float64), tensor(0.0362, dtype=torch.float64), tensor(-0.0290, dtype=torch.float64), tensor(-0.0425, dtype=torch.float64), tensor(0.0623, dtype=torch.float64), tensor(-0.0328, dtype=torch.float64), tensor(-0.0358, dtype=torch.float64), tensor(-0.0509, dtype=torch.float64), tensor(-0.0588, dtype=torch.float64), tensor(-0.0010, dtype=torch.float64), tensor(-0.0241, dtype=torch.float64), tensor(-0.0102, dtype=torch.float64), tensor(-0.0120, dtype=torch.float64), tensor(0.0094, dtype=torch.float64), tensor(0.0880, dtype=torch.float64), tensor(-0.0464, dtype=torch.float64), tensor(0.0455, dtype=torch.float64), tensor(0.0614, dtype=torch.float64), tensor(0.0131, dtype=torch.float64), tensor(-0.0140, dtype=torch.float64), tensor(0.0057, dtype=torch.float64), tensor(-0.0591, dtype=torch.float64), tensor(0.0098, dtype=torch.float64), tensor(0.0202, dtype=torch.float64), tensor(0.0529, dtype=torch.float64), tensor(0.0868, dtype=torch.float64), tensor(-0.0191, dtype=torch.float64), tensor(0.0521, dtype=torch.float64), tensor(0.0858, dtype=torch.float64), tensor(-0.0131, dtype=torch.float64), tensor(-0.0723, dtype=torch.float64), tensor(0.0105, dtype=torch.float64), tensor(0.0811, dtype=torch.float64), tensor(-0.0115, dtype=torch.float64), tensor(0.0422, dtype=torch.float64), tensor(0.0142, dtype=torch.float64), tensor(-0.0142, dtype=torch.float64), tensor(-0.0349, dtype=torch.float64), tensor(0.0067, dtype=torch.float64), tensor(0.0589, dtype=torch.float64), tensor(-0.0234, dtype=torch.float64), tensor(-0.0204, dtype=torch.float64), tensor(-0.0829, dtype=torch.float64), tensor(-0.0272, dtype=torch.float64), tensor(0.0654, dtype=torch.float64), tensor(-0.0194, dtype=torch.float64), tensor(0.0109, dtype=torch.float64), tensor(-0.0210, dtype=torch.float64), tensor(-0.0047, dtype=torch.float64), tensor(-0.0797, dtype=torch.float64), tensor(-0.0058, dtype=torch.float64), tensor(-0.0100, dtype=torch.float64), tensor(-0.0129, dtype=torch.float64), tensor(-0.0032, dtype=torch.float64), tensor(-0.0271, dtype=torch.float64), tensor(-0.0452, dtype=torch.float64), tensor(-0.0255, dtype=torch.float64), tensor(0.0295, dtype=torch.float64), tensor(-0.0757, dtype=torch.float64), tensor(0.0065, dtype=torch.float64), tensor(-0.1235, dtype=torch.float64), tensor(0.0008, dtype=torch.float64), tensor(-0.0496, dtype=torch.float64), tensor(-0.0383, dtype=torch.float64), tensor(0.0033, dtype=torch.float64), tensor(0.0129, dtype=torch.float64), tensor(-0.0019, dtype=torch.float64), tensor(-0.0140, dtype=torch.float64), tensor(0.0491, dtype=torch.float64), tensor(0.0067, dtype=torch.float64), tensor(-0.0123, dtype=torch.float64), tensor(-0.0145, dtype=torch.float64), tensor(-0.0504, dtype=torch.float64), tensor(-0.0149, dtype=torch.float64), tensor(-0.0073, dtype=torch.float64), tensor(-0.0352, dtype=torch.float64), tensor(0.0878, dtype=torch.float64), tensor(-0.0336, dtype=torch.float64), tensor(-0.0634, dtype=torch.float64), tensor(-0.0216, dtype=torch.float64), tensor(0.0112, dtype=torch.float64), tensor(-0.0187, dtype=torch.float64), tensor(0.0006, dtype=torch.float64), tensor(-0.0078, dtype=torch.float64), tensor(-0.0107, dtype=torch.float64), tensor(0.0170, dtype=torch.float64), tensor(-0.0296, dtype=torch.float64), tensor(-0.0045, dtype=torch.float64), tensor(-0.0504, dtype=torch.float64), tensor(-0.0476, dtype=torch.float64), tensor(0.0217, dtype=torch.float64), tensor(0.0301, dtype=torch.float64), tensor(0.0112, dtype=torch.float64), tensor(0.0475, dtype=torch.float64), tensor(0.0002, dtype=torch.float64), tensor(0.0599, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(0.0347, dtype=torch.float64), tensor(-0.0078, dtype=torch.float64), tensor(0.0644, dtype=torch.float64), tensor(-0.0402, dtype=torch.float64), tensor(-0.0374, dtype=torch.float64), tensor(0.0941, dtype=torch.float64), tensor(-0.0340, dtype=torch.float64), tensor(0.0358, dtype=torch.float64), tensor(0.0632, dtype=torch.float64), tensor(-0.0013, dtype=torch.float64), tensor(-0.0561, dtype=torch.float64), tensor(-0.0245, dtype=torch.float64), tensor(-0.0719, dtype=torch.float64), tensor(-0.0125, dtype=torch.float64), tensor(-0.0449, dtype=torch.float64), tensor(0.0667, dtype=torch.float64), tensor(-0.0570, dtype=torch.float64), tensor(-0.0039, dtype=torch.float64), tensor(-0.0266, dtype=torch.float64), tensor(0.0248, dtype=torch.float64), tensor(0.0487, dtype=torch.float64), tensor(0.0689, dtype=torch.float64), tensor(-0.0825, dtype=torch.float64), tensor(-0.0425, dtype=torch.float64), tensor(-0.0189, dtype=torch.float64), tensor(0.0513, dtype=torch.float64), tensor(-0.0627, dtype=torch.float64), tensor(0.0239, dtype=torch.float64), tensor(-0.0152, dtype=torch.float64), tensor(-0.0316, dtype=torch.float64), tensor(-0.0061, dtype=torch.float64), tensor(0.0389, dtype=torch.float64), tensor(0.0422, dtype=torch.float64), tensor(-0.0675, dtype=torch.float64), tensor(0.0166, dtype=torch.float64), tensor(0.0216, dtype=torch.float64), tensor(0.1431, dtype=torch.float64), tensor(0.0313, dtype=torch.float64), tensor(-0.0023, dtype=torch.float64), tensor(0.0735, dtype=torch.float64), tensor(-0.0799, dtype=torch.float64), tensor(-0.0112, dtype=torch.float64), tensor(-0.0312, dtype=torch.float64), tensor(0.0096, dtype=torch.float64), tensor(0.0140, dtype=torch.float64), tensor(0.0373, dtype=torch.float64), tensor(0.0587, dtype=torch.float64), tensor(0.0817, dtype=torch.float64), tensor(-0.0499, dtype=torch.float64), tensor(-0.0077, dtype=torch.float64), tensor(-0.0103, dtype=torch.float64), tensor(-0.0215, dtype=torch.float64), tensor(-0.0046, dtype=torch.float64), tensor(0.0122, dtype=torch.float64), tensor(-0.0846, dtype=torch.float64), tensor(0.0086, dtype=torch.float64), tensor(-0.0584, dtype=torch.float64), tensor(0.0326, dtype=torch.float64), tensor(-0.0524, dtype=torch.float64), tensor(0.0514, dtype=torch.float64), tensor(-0.0153, dtype=torch.float64), tensor(-0.0394, dtype=torch.float64), tensor(-0.1039, dtype=torch.float64), tensor(0.0860, dtype=torch.float64), tensor(0.0252, dtype=torch.float64), tensor(-0.0023, dtype=torch.float64), tensor(0.0924, dtype=torch.float64), tensor(-0.0077, dtype=torch.float64), tensor(0.0583, dtype=torch.float64), tensor(0.0030, dtype=torch.float64), tensor(-0.0788, dtype=torch.float64), tensor(0.0469, dtype=torch.float64), tensor(0.0023, dtype=torch.float64), tensor(-0.0325, dtype=torch.float64), tensor(0.0415, dtype=torch.float64), tensor(0.0342, dtype=torch.float64), tensor(-0.0606, dtype=torch.float64), tensor(0.0239, dtype=torch.float64), tensor(-0.1068, dtype=torch.float64), tensor(-0.0261, dtype=torch.float64), tensor(-0.0199, dtype=torch.float64), tensor(-0.0691, dtype=torch.float64), tensor(-0.0234, dtype=torch.float64), tensor(0.0530, dtype=torch.float64), tensor(-0.0372, dtype=torch.float64), tensor(0.0533, dtype=torch.float64), tensor(-0.0465, dtype=torch.float64), tensor(-0.0411, dtype=torch.float64), tensor(0.0053, dtype=torch.float64), tensor(0.0411, dtype=torch.float64), tensor(-0.0060, dtype=torch.float64), tensor(-0.1187, dtype=torch.float64), tensor(0.0276, dtype=torch.float64), tensor(-0.0014, dtype=torch.float64), tensor(0.0501, dtype=torch.float64), tensor(0.0163, dtype=torch.float64), tensor(-0.0315, dtype=torch.float64), tensor(-0.0834, dtype=torch.float64), tensor(-0.0146, dtype=torch.float64), tensor(-0.0213, dtype=torch.float64), tensor(0.0593, dtype=torch.float64), tensor(-0.0277, dtype=torch.float64), tensor(0.1137, dtype=torch.float64), tensor(-0.0300, dtype=torch.float64), tensor(0.0151, dtype=torch.float64), tensor(-0.0068, dtype=torch.float64), tensor(0.0604, dtype=torch.float64), tensor(-0.0432, dtype=torch.float64), tensor(-0.0386, dtype=torch.float64), tensor(-0.0148, dtype=torch.float64), tensor(-0.0226, dtype=torch.float64), tensor(-0.0652, dtype=torch.float64), tensor(0.0610, dtype=torch.float64), tensor(0.0074, dtype=torch.float64), tensor(0.0367, dtype=torch.float64), tensor(0.0807, dtype=torch.float64), tensor(0.0536, dtype=torch.float64), tensor(-0.0368, dtype=torch.float64), tensor(0.0422, dtype=torch.float64), tensor(0.0013, dtype=torch.float64), tensor(-0.0586, dtype=torch.float64), tensor(-0.0606, dtype=torch.float64), tensor(0.0170, dtype=torch.float64), tensor(0.0662, dtype=torch.float64), tensor(0.0107, dtype=torch.float64), tensor(0.0750, dtype=torch.float64), tensor(0.0038, dtype=torch.float64), tensor(-0.0918, dtype=torch.float64), tensor(0.0682, dtype=torch.float64), tensor(0.1214, dtype=torch.float64), tensor(-0.0927, dtype=torch.float64), tensor(-0.0245, dtype=torch.float64), tensor(0.0145, dtype=torch.float64), tensor(0.0236, dtype=torch.float64), tensor(-0.0912, dtype=torch.float64), tensor(0.0122, dtype=torch.float64), tensor(0.0109, dtype=torch.float64), tensor(0.0100, dtype=torch.float64), tensor(-0.0036, dtype=torch.float64), tensor(0.0612, dtype=torch.float64), tensor(-0.0198, dtype=torch.float64), tensor(-0.0713, dtype=torch.float64), tensor(-0.0033, dtype=torch.float64), tensor(0.0250, dtype=torch.float64), tensor(0.0609, dtype=torch.float64), tensor(0.0448, dtype=torch.float64), tensor(0.0445, dtype=torch.float64), tensor(-0.0346, dtype=torch.float64), tensor(0.0572, dtype=torch.float64), tensor(0.0622, dtype=torch.float64), tensor(0.0093, dtype=torch.float64), tensor(0.0485, dtype=torch.float64), tensor(0.0101, dtype=torch.float64), tensor(-0.0658, dtype=torch.float64), tensor(0.0097, dtype=torch.float64), tensor(0.0275, dtype=torch.float64), tensor(-0.0195, dtype=torch.float64), tensor(0.0148, dtype=torch.float64), tensor(-0.0827, dtype=torch.float64), tensor(-0.0027, dtype=torch.float64), tensor(-0.0364, dtype=torch.float64), tensor(0.0482, dtype=torch.float64), tensor(0.0541, dtype=torch.float64), tensor(0.0179, dtype=torch.float64), tensor(0.0109, dtype=torch.float64), tensor(0.0165, dtype=torch.float64), tensor(-0.0046, dtype=torch.float64), tensor(0.1026, dtype=torch.float64), tensor(0.0146, dtype=torch.float64), tensor(0.0440, dtype=torch.float64), tensor(0.0841, dtype=torch.float64), tensor(-0.0091, dtype=torch.float64), tensor(0.0093, dtype=torch.float64), tensor(0.0504, dtype=torch.float64), tensor(-0.0525, dtype=torch.float64), tensor(-0.0624, dtype=torch.float64), tensor(0.0077, dtype=torch.float64), tensor(-0.0087, dtype=torch.float64), tensor(-0.0127, dtype=torch.float64), tensor(-0.0713, dtype=torch.float64), tensor(0.0673, dtype=torch.float64), tensor(-0.0044, dtype=torch.float64), tensor(-0.0580, dtype=torch.float64), tensor(0.0149, dtype=torch.float64), tensor(-0.0142, dtype=torch.float64), tensor(-0.0114, dtype=torch.float64), tensor(0.0907, dtype=torch.float64), tensor(0.0908, dtype=torch.float64), tensor(0.0984, dtype=torch.float64), tensor(-0.1089, dtype=torch.float64), tensor(0.0258, dtype=torch.float64), tensor(-0.0457, dtype=torch.float64), tensor(-0.0076, dtype=torch.float64), tensor(0.0092, dtype=torch.float64), tensor(-0.0408, dtype=torch.float64), tensor(-0.0020, dtype=torch.float64), tensor(-0.0745, dtype=torch.float64), tensor(0.0212, dtype=torch.float64), tensor(0.0328, dtype=torch.float64), tensor(-0.0028, dtype=torch.float64), tensor(-0.0893, dtype=torch.float64), tensor(-0.1012, dtype=torch.float64), tensor(0.0002, dtype=torch.float64), tensor(0.0541, dtype=torch.float64), tensor(0.0470, dtype=torch.float64), tensor(0.0903, dtype=torch.float64), tensor(-0.0057, dtype=torch.float64), tensor(0.0131, dtype=torch.float64), tensor(-0.0577, dtype=torch.float64), tensor(-0.0136, dtype=torch.float64), tensor(-0.0178, dtype=torch.float64), tensor(-0.0656, dtype=torch.float64), tensor(0.0535, dtype=torch.float64), tensor(-0.0093, dtype=torch.float64), tensor(-0.0506, dtype=torch.float64), tensor(-0.0298, dtype=torch.float64), tensor(0.0857, dtype=torch.float64), tensor(0.0534, dtype=torch.float64), tensor(0.0047, dtype=torch.float64), tensor(0.0181, dtype=torch.float64), tensor(0.0221, dtype=torch.float64), tensor(0.0160, dtype=torch.float64), tensor(0.0445, dtype=torch.float64), tensor(-0.0545, dtype=torch.float64), tensor(0.0152, dtype=torch.float64), tensor(0.0034, dtype=torch.float64), tensor(0.0035, dtype=torch.float64), tensor(0.0827, dtype=torch.float64), tensor(-0.0409, dtype=torch.float64), tensor(0.0234, dtype=torch.float64), tensor(-0.0120, dtype=torch.float64), tensor(0.0361, dtype=torch.float64), tensor(-0.0914, dtype=torch.float64), tensor(0.0205, dtype=torch.float64), tensor(-0.0494, dtype=torch.float64), tensor(-0.0147, dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2dcb2",
   "metadata": {},
   "source": [
    "# Model and Guide Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7365859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_converged(arr):\n",
    "    if len(arr) < 2:\n",
    "        return False\n",
    "    # check if last values have changed by 1% or less\n",
    "    return (max(arr) - min(arr)) / max(arr) < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3c9ca124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_converged([3, 3.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb588b8",
   "metadata": {},
   "source": [
    "Warm starting can be done by replacing anything that's a hard coded value:\n",
    "- mu0: torch.zeros\n",
    "- b: torch.ones\n",
    "- beta: mu (torch.zeroes), 0\n",
    "- std: the 1 in dist.HalfNormal(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3d61d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # define the hyperparameters that control the Beta prior\n",
    "    mu0 = torch.zeros(dim, dtype=torch.float64)\n",
    "    bmean = torch.ones(dim, dtype=torch.float64)\n",
    "    bscale = torch.ones(dim, dtype=torch.float64)\n",
    "    b = pyro.sample(\"b\", dist.Gamma(bmean, bscale).to_event(1))\n",
    "    # sample f from the Beta prior\n",
    "    beta = pyro.sample(\"beta\", dist.Laplace(mu0, b).to_event(1))\n",
    "    std_scale = 1\n",
    "    std = pyro.sample(\"sigma\", dist.HalfNormal(std_scale))\n",
    "    # loop over the observed data\n",
    "    # subset = random.sample(data, int(len(data) / dim))\n",
    "    # for i in range(len(subset)):\n",
    "    # data goes list tuple tensor\n",
    "          \n",
    "    with pyro.plate(\"data\", len(data), subsample_size=100) as ind:\n",
    "        data = np.asarray(data)[ind]\n",
    "        for i in range(len(data)):\n",
    "            sampler = dist.Normal(beta.dot(data[i][0]).item(), std)\n",
    "            pyro.sample(\"obs_{}\".format(i), sampler.to_event(0), obs=data[i][1])\n",
    "\n",
    "# Global guide\n",
    "guide = pyro.infer.autoguide.AutoLaplaceApproximation(poutine.block(model, expose=['b', 'beta', 'sigma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fa57e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVI(D_hat, n_steps, warm_dict = None):    \n",
    "    losses = []\n",
    "    # setup the optimizer\n",
    "    adam_params = {\"lr\": 0.005, \"betas\": (0.90, 0.999)}\n",
    "    optimizer = Adam(adam_params)\n",
    "\n",
    "    # setup the inference algorithm\n",
    "    guide = pyro.infer.autoguide.AutoLaplaceApproximation(poutine.block(model, expose=['b', 'beta', 'sigma']))\n",
    "    if warm_dict is not None:\n",
    "        guide = pyro.infer.autoguide.AutoLaplaceApproximation(poutine.block(model, expose=['b', 'beta', 'sigma']), init_loc_fn=init_to_value(values=warm_dict))\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "    # do gradient steps\n",
    "    for step in range(n_steps):\n",
    "        loss = svi.step(D_hat)\n",
    "        losses.append(loss)\n",
    "        if is_converged(losses[-1:-6:-1]):\n",
    "            print(f\"Converged on step {step} -- breaking\")\n",
    "            break\n",
    "        if loss < 1e-5:\n",
    "            print(f\"Early Loss Stopping on step {step}\")\n",
    "            break\n",
    "    beta = guide(D_hat)['beta']\n",
    "    print(f\"Ended on step {step}\")\n",
    "    return beta, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "53da63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "93847df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/1mkc4t8137lbs9x8hhg9q8940000gp/T/ipykernel_86325/3602142821.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.asarray(data)[ind]\n",
      "/var/folders/1s/1mkc4t8137lbs9x8hhg9q8940000gp/T/ipykernel_86325/3602142821.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.asarray(data)[ind]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b': tensor([0.6519, 0.6946, 0.9197, 0.9505, 0.7291, 0.3914, 0.7772, 0.4084, 0.7029,\n",
       "         0.9446], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'beta': tensor([ 0.1011, -0.2394,  0.1339,  0.0180, -0.1239, -0.2752, -0.2277,  0.1728,\n",
       "         -0.1173, -0.0470], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'sigma': tensor(0.6690, dtype=torch.float64, grad_fn=<ExpandBackward0>)}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide(D_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094040c8",
   "metadata": {},
   "source": [
    "# Run VI on Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "75c8441a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1290, dtype=torch.float64)\n",
      "tensor(-0.1548, dtype=torch.float64)\n",
      "tensor(0.1290, dtype=torch.float64)\n",
      "tensor(-0.1548, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/1mkc4t8137lbs9x8hhg9q8940000gp/T/ipykernel_86325/3602142821.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.asarray(data)[ind]\n",
      "/var/folders/1s/1mkc4t8137lbs9x8hhg9q8940000gp/T/ipykernel_86325/3602142821.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.asarray(data)[ind]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended on step 99\n",
      "0.12899003328897318 Not added\n",
      "Early Loss Stopping on step 5\n",
      "Ended on step 5\n",
      "0.11899003328897319 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.10899003328897319 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.0989900332889732 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.0889900332889732 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.07899003328897321 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.06899003328897321 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.05899003328897321 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.04899003328897321 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.03899003328897321 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.028990033288973205 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.018990033288973203 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "0.008990033288973203 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.0010099667110267975 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.011009966711026798 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.021009966711026798 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.0310099667110268 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.0410099667110268 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.051009966711026804 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.061009966711026806 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.0710099667110268 Added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.0810099667110268 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.09100996671102679 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.10100996671102679 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.11100996671102678 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.12100996671102678 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.13100996671102677 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.14100996671102678 Not added\n",
      "Early Loss Stopping on step 0\n",
      "Ended on step 0\n",
      "-0.1510099667110268 Not added\n"
     ]
    }
   ],
   "source": [
    "rank_proportions = []\n",
    "y_hat = max(Y_train)\n",
    "y_bottom = min(Y_train)\n",
    "print(y_hat)\n",
    "print(y_bottom)\n",
    "conformal_set = []\n",
    "decrease_size = 0.01\n",
    "start = time.time()\n",
    "print(max(Y_train))\n",
    "print(min(Y_train))\n",
    "prev_d_hat = None\n",
    "all_losses = []\n",
    "while y_hat >= y_bottom:\n",
    "    pyro.clear_param_store()\n",
    "    # Create D_hat\n",
    "    D_hat = list(zip(X_train[:-1], Y_train))\n",
    "    D_hat.append((X_train[-1], y_hat))\n",
    "    \n",
    "    # Train SVI\n",
    "    warm_dict = guide(D_hat)\n",
    "    if warm_dict is not None:\n",
    "        beta, losses = train_SVI(D_hat, 100, warm_dict)\n",
    "    else:\n",
    "        print(\"Warm dict was none\")\n",
    "        beta, losses = train_SVI(D_hat, 100)\n",
    "    all_losses.append(losses)\n",
    "    \n",
    "    \n",
    "    # Calculate rank of y_hat\n",
    "    rank = [(abs(sum(D_hat[i][0] * beta) - D_hat[i][1]).detach().numpy()) for i in range(len(D_hat))]\n",
    "    y_hat_rank = rank[-1]\n",
    "    \n",
    "    # Add to conformal set if in not in bottom 10 percent of probabilities\n",
    "    current_rank_proportion = np.count_nonzero(y_hat_rank > rank) / len(rank)\n",
    "    rank_proportions.append(current_rank_proportion)\n",
    "    if current_rank_proportion < 0.9:\n",
    "        conformal_set.append(copy.deepcopy(y_hat))\n",
    "        print(f\"{y_hat} Added\")\n",
    "    else:\n",
    "        print(f\"{y_hat} Not added\")\n",
    "    y_hat -= decrease_size\n",
    "conformal_set = [min(conformal_set), max(conformal_set)]\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "755e7a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformal Set: [-0.0710099667110268, 0.07899003328897321]\n",
      "Length: 0.15000000000000002\n",
      "Y[-1]: -0.06333268566531168\n",
      "Y[-1] is covered\n",
      "Elapsed Time: 5.692325830459595\n"
     ]
    }
   ],
   "source": [
    "print(f\"Conformal Set: [{float(conformal_set[0])}, {float(conformal_set[1])}]\")\n",
    "print(f\"Length: {float(conformal_set[1] - conformal_set[0])}\")\n",
    "print(f\"Y[-1]: {last_y}\")\n",
    "if Y[-1] >= conformal_set[0] and Y[-1] <= conformal_set[1]:\n",
    "    print(f\"Y[-1] is covered\")\n",
    "else:\n",
    "    print(\"Y[-1] is Not covered\")\n",
    "print(f\"Elapsed Time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f2ed7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23120.853266492224, 22851.71527529486, 22640.494219306533, 22434.32974161592, 22192.010076785842, 21985.35133724296, 21760.128015530896, 21536.985067065907, 21298.854902772135, 21072.633514318386, 20837.33023343881, 20666.59964201703, 20422.833740241047, 20204.024907136543, 19980.60332735298, 19784.805203473457, 19517.670695150908, 19343.509417553563, 19129.241519647934, 18898.936111342686, 18658.280939220116, 18416.80924872754, 18228.904888265693, 18003.447480338913, 17766.683939985607, 17538.849631543253, 17311.455075234724, 17083.562017670447, 16888.05573128119, 16645.137686446946, 16442.58316380719, 16224.353733827053, 16035.018562901323, 15758.64612960534, 15583.588122704563, 15349.311550069538, 15110.785225751464, 14889.663241142647, 14630.563456915808, 14436.958723786596, 14213.04776680513, 13998.33693104886, 13778.859339473558, 13574.159466216024, 13402.23272103334, 13114.560912885632, 12887.879588185146, 12710.28800395898, 12460.061808344923, 12223.901810371903, 12030.612494856094, 11826.03497104419, 11612.261926426298, 11357.908811807529, 11126.651349805808, 10974.758454450937, 10692.442197521936, 10486.189503156327, 10282.099004493188, 9978.854032663836, 9871.476310231232, 9612.777224354211, 9396.572844884338, 9134.647239672366, 8951.58645132314, 8750.189091446382, 8503.094591099589, 8297.694256013134, 8097.2231295972815, 7876.811076742634, 7637.297929028023, 7395.476956993216, 7209.5305104033605, 7002.64964299086, 6744.388433093672, 6585.1223187093065, 6293.712378393064, 6092.01657131298, 5874.073809956237, 5681.67586783604, 5448.891265788936, 5194.234624895914, 4996.203052866411, 4769.6215082980425, 4602.141323932956, 4320.404060111583, 4126.263843692454, 3934.3919863081815, 3737.570471815002, 3461.036609129298, 3260.221475580248, 3012.695592323189, 2876.2040527593786, 2564.7184178576017, 2396.585886786788, 2187.781174646071, 1941.3793234842396, 1687.246960333674, 1573.198264305535, 1316.1514589031563]\n"
     ]
    }
   ],
   "source": [
    "print(all_losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f8e9ba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9932279909706546,\n",
       " 0.9864559819413092,\n",
       " 0.9751693002257337,\n",
       " 0.9661399548532731,\n",
       " 0.9413092550790068,\n",
       " 0.8871331828442438,\n",
       " 0.8555304740406321,\n",
       " 0.7765237020316027,\n",
       " 0.6975169300225733,\n",
       " 0.5936794582392777,\n",
       " 0.4785553047404063,\n",
       " 0.327313769751693,\n",
       " 0.17607223476297967,\n",
       " 0.013544018058690745,\n",
       " 0.1986455981941309,\n",
       " 0.3611738148984199,\n",
       " 0.4966139954853273,\n",
       " 0.6139954853273137,\n",
       " 0.7065462753950339,\n",
       " 0.7945823927765236,\n",
       " 0.8577878103837472,\n",
       " 0.9006772009029346,\n",
       " 0.9480812641083521,\n",
       " 0.9661399548532731,\n",
       " 0.9841986455981941,\n",
       " 0.9887133182844243,\n",
       " 0.9932279909706546,\n",
       " 0.9909706546275395,\n",
       " 0.9954853273137697]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ba3d2fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(rank_proportions)), rank_proportions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "386fe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_hat = list(zip(X_train[:-1], Y_train))\n",
    "D_hat.append((X_train[-1], y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "964e7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0168, 0.0460, 0.0575, 0.0287, 0.0530, 0.0415, 0.0002, 0.0078, 0.0458,\n",
      "        0.0029], dtype=torch.float64), tensor(-0.1610, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "print(D_hat[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "296c6586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': tensor([0.3424, 0.3483, 0.4851, 0.5083, 0.3823, 0.2447, 0.3970, 0.2013, 0.3687,\n",
       "         0.5043], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'beta': tensor([ 0.0035, -0.0041,  0.0036,  0.0039, -0.0038, -0.0044, -0.0034, -0.0041,\n",
       "         -0.0039, -0.0034], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'sigma': tensor(0.3442, dtype=torch.float64, grad_fn=<ExpandBackward0>)}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide(D_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "739f29a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoLaplaceApproximation()"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "139bd289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': tensor([0.3424, 0.3483, 0.4851, 0.5083, 0.3823, 0.2447, 0.3970, 0.2013, 0.3687,\n",
       "         0.5043], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'beta': tensor([ 0.0035, -0.0041,  0.0036,  0.0039, -0.0038, -0.0044, -0.0034, -0.0041,\n",
       "         -0.0039, -0.0034], dtype=torch.float64, grad_fn=<ExpandBackward0>),\n",
       " 'sigma': tensor(0.3442, dtype=torch.float64, grad_fn=<ExpandBackward0>)}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide(D_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb1f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
